#!/usr/bin/python
from sys import *
from socket import *
from HTMLParser import HTMLParser
import re


username = ""
password = ""

url = "fring.ccs.neu.edu"
port = 80


visited_urls = ["/fakebook/", "/fakebook"]
urls_to_visit = []

secret_flags = []

session_id = ""

number_of_GET = 0


CSRF_token = ""
CSRF_flag = False
setrecursionlimit(5000)


class ResponseHTMLParser(HTMLParser):
    def handle_starttag(self, tag, attrs):
        if tag == "input":
            for name, value in attrs:
                global CSRF_token
                global CSRF_flag
                if CSRF_flag == True:
                    CSRF_token = value
                    CSRF_flag = False
                if value == "csrfmiddlewaretoken":
                    CSRF_flag = True

class AHTMLParser(HTMLParser):
    def handle_starttag(self, tag, attrs):
        if tag == 'a':
            for name, value in attrs:
                if name == 'href':
                    global visited_urls
                    global urls_to_visit
                    if re.search('/fakebook/', value) != None:
                        link = re.search('/fakebook/.*', value)
                        link = link.group()
                    else:
                        return
                            
                    if link not in visited_urls:
                        urls_to_visit.append(link)
                        return link
                    else:
                        return None

class SecretFlagHTMLParser(HTMLParser):
    is_secret_flag = False
    def handle_starttag(self, tag, attrs):
        if tag == 'h2':
            for name, value in attrs:
                if name == 'class' and value == 'secret_flag':
                    self.is_secret_flag = True
    def handle_data(self, data):
        global secret_flags
        if self.is_secret_flag == True:
            flag = data[6:]
            if flag not in secret_flags:
                print "FOUND FLAG:" + flag
                secret_flags.append(flag)
            self.is_secret_flag = False

## Crawl html pages
def crawl():
    ## Socket connection
    sock = socket(AF_INET, SOCK_STREAM)
    sock.connect((url, port))
    
    ## Get login response
    login_res = get('/accounts/login/?next=/fakebook/', sock)
    
    ## Instance of HTMLParser for response
    res_parser = ResponseHTMLParser()
    
    ## Get sesssion id
    calc_session_id(login_res)
    ## Feed login reponse to the parser
    res_parser.feed(login_res)
    
    ## Get POST login response
    post_res = post_login(sock)
    calc_session_id(post_res)
    
    ## Look for secret flags
    find_secret_flags(sock)

## Checks given response res for HTTP code and returns it
def check_code(res):
    global urls_to_visit
    if "200 OK" in res:
        return 200

    ## Redirect
    elif "301 MOVED" in res:
        calc_session_id(res)
        ## Search for Location header
        re_match = re.search(r'[.\s]*Location: .*', res)
        if re_match == None:
            return 301

        ## Find new URL 
        re_match = re_match.group()
        re_match = re.search(r'\.edu/.*', ret)
        if re_match == None:
            return 301 
        re_match = re_match.group()
        #length = len(re_match)
        re_match = re_match[4:]
        if re_match not in urls_to_visit:
            urls_to_visit.append(re_match)
        return 301

    ## Abandon URLS
    elif "404 NOT FOUND" in res:
        return 404 
    elif "403 FORBIDDEN" in res:
        return 403

    ## Retry request
    elif "500 INTERNAL SERVER ERROR" in res:
        return 500 
     
    return 200 
        
## Prints secret flags if there are 5 of them
def check_flags():
    global secret_flags
    if len(secret_flags) == 5:
        for f in secret_flags:                
            print f
        exit()

## Looks for secret flags
def find_secret_flags(sock):
    global urls_to_visit
    global number_of_GET
    global visited_urls

    ## Get response from GET request
    res = get('/fakebook/', sock)
    ## Create an instance of HTML Parser for links
    a_parser = AHTMLParser()
    ## Feed response to parser
    a_parser.feed(res)
    
    ## Create an instance of HTML Parser for secret flags
    secret_flag_parser = SecretFlagHTMLParser()

    for url in urls_to_visit:
        ## Get response from GET request for given url
        get_res = get(url, sock)
        ## Check for HTTP code
        code = check_code(get_res)
        #print code
        if number_of_GET % 99 == 0:
            #print "999999999999999999999"
            break
        if code == 200:
            a_parser.feed(get_res)
            secret_flag_parser.feed(get_res)
            if url in urls_to_visit:
                urls_to_visit.remove(url)
            visited_urls.append(url)
        elif code == 500:
            break
        elif (code == 301 or code == 403 or code == 404):
            urls_to_visit.remove(url)
            continue
        check_flags()
    crawl()

## Find sessionid in HTML
def calc_session_id(res):
    re_match = re.search(r'sessionid=[A-Za-z0-9]{32}', res)
    if re_match != None:
        global session_id
        re_match = re_match.group()
        #print "session id "+ re_match
        s_id = re_match[10:]
        session_id = s_id

## POST request to login page
def post_login(sock):
    global username
    global password
    global session_id
    global CSRF_token
    global CSRF_flag
    message = "POST /accounts/login/?next=/fakebook/ HTTP/1.1\r\n" + "Host:fring.ccs.neu.edu:80\r\nReferer:http://fring.ccs.neu.edu/accounts/login/?next=/fakebook/\r\nCookie:csrftoken="+CSRF_token+"; sessionid="+session_id+"\r\nConnection:keep-alive\r\nContent-Type: application/x-www-form-urlencoded\r\nContent-Length: 109\r\n\r\ncsrfmiddlewaretoken="+CSRF_token+"&username="+username+"&password="+password+"&next=%2Ffakebook%2F\r\n\r\n"
    #print message
    sock.sendall(message)
    res = sock.recv(10000)
    return res

## GET request for given url
def get(link, sock):
    global number_of_GET
    global CSRF_token
    global session_id
    global url
    number_of_GET += 1
    message = "GET " + link + " HTTP/1.1\r\nHost: " + url + "\r\nCookie: csrftoken=" + CSRF_token + "; sessionid=" + session_id + "\r\nConnection:keep-alive\r\n\r\n"
    #print message
    sock.sendall(message)
    return sock.recv(10000)


if __name__ == "__main__":
    if len(argv) == 3:
        global username
        global password
        username = argv[1]
        password = argv[2]
        crawl()
    else:
        print "Wrong format! Please type ./webcrawler username password"
